{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0e7cf524",
      "metadata": {
        "id": "0e7cf524"
      },
      "source": [
        "# PROJECT STARTS HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13f5a983",
      "metadata": {
        "id": "13f5a983"
      },
      "source": [
        "# Importing Libraries and Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9fea4e4c",
      "metadata": {
        "id": "9fea4e4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dr2007\\AppData\\Local\\Temp\\ipykernel_6052\\2279094380.py:10: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "# import mediapipe as mp\n",
        "# import csv\n",
        "# import dill\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "08f9dd68",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dr2007\\AppData\\Local\\Temp\\ipykernel_17560\\2537256825.py:1: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "# import pandas as pd\n",
        "# !pip3 install --upgrade pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qzZnzDEZ6EMD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzZnzDEZ6EMD",
        "outputId": "50b78854-bbd7-465e-a18f-20ba0499c96e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "vFlxKLir5VJW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFlxKLir5VJW",
        "outputId": "983e6b9d-388f-4899-c984-31125d28782e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Feb 20 16:47:45 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 546.12                 Driver Version: 546.12       CUDA Version: 12.3     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA GeForce RTX 2080      WDDM  | 00000000:01:00.0  On |                  N/A |\n",
            "| 25%   32C    P8              21W / 215W |    449MiB /  8192MiB |     11%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A      1836    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
            "|    0   N/A  N/A      1932    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A      7076    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
            "|    0   N/A  N/A     11504    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A     12336    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A     12796    C+G   ...up\\ui-launcher\\AdskAccessUIHost.exe    N/A      |\n",
            "|    0   N/A  N/A     13724    C+G   ...s\\Autodesk\\Autodesk AdSSO\\AdSSO.exe    N/A      |\n",
            "|    0   N/A  N/A     13988    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A     14992    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     16604    C+G   ...on\\HEX\\Creative Cloud UI Helper.exe    N/A      |\n",
            "|    0   N/A  N/A     19164    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "89327d46",
      "metadata": {
        "id": "89327d46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.4.1.post1-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\dr2007\\.conda\\envs\\test_env_gpu\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dr2007\\.conda\\envs\\test_env_gpu\\lib\\site-packages (from scikit-learn) (1.11.3)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
            "  Downloading threadpoolctl-3.3.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scikit_learn-1.4.1.post1-cp39-cp39-win_amd64.whl (10.6 MB)\n",
            "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
            "   --- ------------------------------------ 1.0/10.6 MB 33.0 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 3.7/10.6 MB 46.9 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 7.1/10.6 MB 56.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  10.6/10.6 MB 65.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 10.6/10.6 MB 59.5 MB/s eta 0:00:00\n",
            "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
            "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
            "   --------------------------------------- 302.2/302.2 kB 18.2 MB/s eta 0:00:00\n",
            "Downloading threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
            "Successfully installed joblib-1.3.2 scikit-learn-1.4.1.post1 threadpoolctl-3.3.0\n"
          ]
        }
      ],
      "source": [
        "# !pip3 install opencv-python\n",
        "# !pip3 install dill\n",
        "# !pip3 install matplotlib\n",
        "# !pip3 install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3543af3",
      "metadata": {
        "id": "c3543af3",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# To save variable of the last session (avoid re-executing the cells)\n",
        "# dill.dump_session('base_variables3.db')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54c5f7e7",
      "metadata": {
        "id": "54c5f7e7"
      },
      "outputs": [],
      "source": [
        "# To load session variables\n",
        "# dill.load_session('base_variables3.db')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VZtO4i_r81hP",
      "metadata": {
        "id": "VZtO4i_r81hP"
      },
      "outputs": [],
      "source": [
        "# !unzip '/content/drive/MyDrive/NEW_MP_Frames.zip' > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e195f4da",
      "metadata": {
        "id": "e195f4da"
      },
      "source": [
        "# Frame Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7317d5c2",
      "metadata": {
        "id": "7317d5c2"
      },
      "outputs": [],
      "source": [
        "# Folder path of dataset\n",
        "folder_path = r'D:\\FYP_HWU\\Videos'\n",
        "DATA_PATH = r'D:\\FYP_HWU'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b6b0e03",
      "metadata": {
        "id": "4b6b0e03"
      },
      "outputs": [],
      "source": [
        "# List of actions to train model with (11 classes or actions)\n",
        "actions = [\n",
        "'accident',\n",
        "'call',\n",
        "'help',\n",
        "'man',\n",
        "'murder',\n",
        "'woman',\n",
        "'danger',\n",
        "'police',\n",
        "'follow',\n",
        "'child',\n",
        "'sick'\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61c87b66",
      "metadata": {
        "id": "61c87b66"
      },
      "outputs": [],
      "source": [
        "temp_actions = ['follow', 'child','police']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "472179a6",
      "metadata": {
        "id": "472179a6",
        "outputId": "734663c9-37c9-4ec3-d26a-73c6a33a3c14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(temp_actions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6ae7098",
      "metadata": {
        "id": "b6ae7098"
      },
      "source": [
        "### Counting number of videos under each action in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fac5687",
      "metadata": {
        "id": "2fac5687"
      },
      "outputs": [],
      "source": [
        "# folder_path = r'C:\\Users\\dr2007\\Documents\\FYP_HWU\\Aug_Frames'\n",
        "folder_path = r'D:\\WLASL Datasets\\Kaggle_WLASL_withVideosInClassFolders\\dataset\\SL'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "256c79e4",
      "metadata": {
        "id": "256c79e4",
        "outputId": "c2991df3-07a9-4acd-9f4f-14663763c863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'accident': 13, 'call': 12, 'child': 9, 'danger': 11, 'follow': 9, 'help': 14, 'man': 12, 'murder': 13, 'police': 10, 'sick': 10, 'woman': 11}\n"
          ]
        }
      ],
      "source": [
        "# Initializing variables\n",
        "video_count = {}\n",
        "folder_path = r'D:\\FYP_HWU\\NEW_Frames'\n",
        "\n",
        "# Creating a dictionary for all the actions/classes along with the count of videos for each action in the dataset\n",
        "for root, dirs, files in os.walk(folder_path):\n",
        "    for i in dirs: #loop through each of the keywords or actions in the dataset\n",
        "        if (i in actions): #if the keyword is present in the shortlisted list of actions\n",
        "            for root, dirs, files in os.walk(os.path.join(folder_path, i)):\n",
        "                video_count[i] = len(dirs)\n",
        "                break\n",
        "    break\n",
        "\n",
        "print(video_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb5e3aaa",
      "metadata": {
        "id": "fb5e3aaa"
      },
      "outputs": [],
      "source": [
        "# Initializing variables\n",
        "video_count = {}\n",
        "first_11_items = {}\n",
        "\n",
        "# Creating a dictionary for all the actions/classes along with the count of videos for each action in the dataset\n",
        "for root, dirs, files in os.walk(folder_path):\n",
        "    for i in dirs: #loop through each of the keywords or actions in the dataset\n",
        "        for root, dirs, files in os.walk(os.path.join(folder_path, i)):\n",
        "            video_count[i] = len(files)\n",
        "            break\n",
        "\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e0a8806",
      "metadata": {
        "id": "4e0a8806"
      },
      "outputs": [],
      "source": [
        "video_count1 = sorted(video_count.items(), key=lambda x:x[1], reverse = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5a166d7",
      "metadata": {
        "id": "f5a166d7",
        "outputId": "f97100e7-a381-42d2-c7ef-ba480adf2584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'cousin': 17, 'before': 16, 'cool': 16, 'thin': 16, 'drink': 15, 'go': 15, 'computer': 14, 'help': 14, 'inform': 14, 'take': 14, 'who': 14}\n"
          ]
        }
      ],
      "source": [
        "for idx, k in enumerate(video_count1):\n",
        "    if idx == 11: break\n",
        "    first_11_items[k[0]] = k[1]\n",
        "\n",
        "print(first_11_items)\n",
        "# print(video_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5d4fdf7",
      "metadata": {
        "id": "d5d4fdf7"
      },
      "outputs": [],
      "source": [
        "# print(video_count1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95624701",
      "metadata": {
        "id": "95624701"
      },
      "outputs": [],
      "source": [
        "# video_count = {'accident': 13, 'call': 12, 'child': 9, 'danger': 11, 'help': 14, 'man': 12, 'murder': 13, 'police': 10, 'sick': 10, 'woman': 11}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2524b96f",
      "metadata": {
        "id": "2524b96f"
      },
      "outputs": [],
      "source": [
        "temp_video_count = {'follow': 36, 'child': 36, 'police': 40}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "147cfdda",
      "metadata": {
        "id": "147cfdda",
        "outputId": "577189d6-e765-41cc-db73-dca79f3bfe50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(temp_video_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "086f9e04",
      "metadata": {
        "id": "086f9e04"
      },
      "source": [
        "### Getting the video paths of the videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f80710ca",
      "metadata": {
        "id": "f80710ca"
      },
      "outputs": [],
      "source": [
        "video_paths = {}\n",
        "\n",
        "# Creating a dictionary for all the actions/classes along with the count of videos for each action in the dataset\n",
        "for root, dirs, files in os.walk(folder_path):\n",
        "\n",
        "    for action in actions:\n",
        "        for root, dirs, files in os.walk(os.path.join(folder_path, action)):\n",
        "            for i in range (len(files)):\n",
        "                files[i] = os.path.join(folder_path, action, files[i])\n",
        "            video_paths[action] = files\n",
        "            break\n",
        "    break\n",
        "\n",
        "# print(video_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64a6099e",
      "metadata": {
        "id": "64a6099e"
      },
      "outputs": [],
      "source": [
        "# converting the folderpaths to csv file\n",
        "df = pd.DataFrame.from_dict(video_paths, orient='index')\n",
        "df = df.transpose()\n",
        "df.to_csv('video_paths.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5827ab0e",
      "metadata": {
        "id": "5827ab0e"
      },
      "outputs": [],
      "source": [
        "# Reading a csv file to get the video paths\n",
        "def read_csv_to_dict(csv_file):\n",
        "    result_dict = {}\n",
        "\n",
        "    with open(csv_file, 'r') as file:\n",
        "        csv_reader = csv.reader(file)\n",
        "\n",
        "        # Read the header row to get the keys\n",
        "        keys = next(csv_reader, None)\n",
        "        if keys:\n",
        "            for key in keys:\n",
        "                result_dict[key] = []\n",
        "\n",
        "            # Read the rest of the rows and store values in the dictionary\n",
        "            for row in csv_reader:\n",
        "                for i in range(len(keys)):\n",
        "                    result_dict[keys[i]].append(row[i])\n",
        "\n",
        "    return result_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b7353fa",
      "metadata": {
        "id": "6b7353fa"
      },
      "outputs": [],
      "source": [
        "video_paths = read_csv_to_dict(\"video_paths.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4317688",
      "metadata": {
        "collapsed": true,
        "id": "e4317688"
      },
      "outputs": [],
      "source": [
        "print(temp_video_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0144d09",
      "metadata": {
        "id": "c0144d09"
      },
      "outputs": [],
      "source": [
        "# print(video_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dc1285b",
      "metadata": {
        "id": "0dc1285b"
      },
      "source": [
        "### Creating folders to store frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50bd1108",
      "metadata": {
        "id": "50bd1108"
      },
      "outputs": [],
      "source": [
        "#Creating folder 'Frames' that will contain all the video frames\n",
        "# os.makedirs(os.makedirs(os.path.join(DATA_PATH,'Frames')))\n",
        "# os.makedirs(os.path.join(DATA_PATH,'Original_Frames'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d648538",
      "metadata": {
        "collapsed": true,
        "id": "8d648538"
      },
      "outputs": [],
      "source": [
        "#Creating folder 'NEW_Frames' that will contain all the video frames\n",
        "DATA_PATH = r'D:\\FYP_HWU'\n",
        "os.makedirs(os.path.join(DATA_PATH,'NEW_Frames'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "685c8ed0",
      "metadata": {
        "id": "685c8ed0"
      },
      "outputs": [],
      "source": [
        "#Creating one folder for each action\n",
        "for action in video_paths.keys():\n",
        "    # 1 folder for each video of the action\n",
        "    for sequence in range(len(video_paths[action])):\n",
        "        try:\n",
        "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
        "        except:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9e300d2",
      "metadata": {
        "id": "b9e300d2"
      },
      "source": [
        "## Extracting frames from videos and adding them to folders"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b725def",
      "metadata": {
        "id": "3b725def"
      },
      "source": [
        "### APPROACH 1\n",
        "Here, a fixed number of frames are extracted from each video (60 in the current case). If the extracted frames from a video are less than 60, then the last frame is repeated to reach the 60 count. If the video is too long, then then the first 60 frames of the video will be extracted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7761ec4",
      "metadata": {
        "id": "f7761ec4"
      },
      "outputs": [],
      "source": [
        "#looping through each action\n",
        "for action in video_paths.keys():\n",
        "\n",
        "    #Looping through each video of the action\n",
        "    for sequence in range(len(video_paths[action])):\n",
        "\n",
        "        # Open the video file\n",
        "        cap = cv2.VideoCapture(video_paths[action][sequence])\n",
        "\n",
        "        # Initializing variables\n",
        "        frame_count = 0       # current frame count\n",
        "        max_fc = 60          # maximum frame count\n",
        "\n",
        "\n",
        "        #while the video is accessible and the current frame count doesn't exceed the max frame count limit\n",
        "        while (cap.isOpened() and frame_count < max_fc):\n",
        "            #reading the video frame\n",
        "            success, frame = cap.read()\n",
        "\n",
        "            #if there are frames\n",
        "            if success:\n",
        "                image = frame.copy()\n",
        "                cv2.imshow(\"{} - {}\".format(action, sequence), image)\n",
        "\n",
        "                #saving the extracted frames (in jpg format)\n",
        "                cv2.imwrite(os.path.join(DATA_PATH , action, str(sequence), 'frame'+ str(frame_count) + '.jpg'), image)\n",
        "                frame_count+=1\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        # repeat last frame until we reach max frame count\n",
        "        while frame_count < max_fc:\n",
        "            cv2.imwrite(os.path.join(DATA_PATH , action, str(sequence), 'frame'+ str(frame_count) + '.jpg'), image)\n",
        "            frame_count+=1\n",
        "\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4526c39",
      "metadata": {
        "id": "d4526c39"
      },
      "source": [
        "### APPROACH 2\n",
        "Here too, a fixed number of frames are extracted from each video (20 in the current case). The frames will be extracted after dividing the complete video into equal parts and then choosing the frames from each part. This way we will be able to avoid the first few or last frames few of the video if no action is being depicted. Secondly, the basic movement of the action is captured."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eec91fc",
      "metadata": {
        "id": "8eec91fc"
      },
      "outputs": [],
      "source": [
        "# how many frames to extract?\n",
        "count = []\n",
        "for action in video_paths.keys():\n",
        "        #Looping through each video of the action\n",
        "        for sequence in range(len(video_paths[action])):\n",
        "            cap = cv2.VideoCapture(video_paths[action][sequence])\n",
        "            total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "            count.append(total_frames)\n",
        "            cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80df5fac",
      "metadata": {
        "id": "80df5fac",
        "outputId": "3724ecc9-3fdc-4cff-b84d-dea6f826e992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25.0\n"
          ]
        }
      ],
      "source": [
        "print(min(count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b3c8ad5",
      "metadata": {
        "id": "2b3c8ad5",
        "outputId": "29c9d7d2-0a94-4422-d199-4fa995f47937"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "155.0\n"
          ]
        }
      ],
      "source": [
        "print(max(count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceb71138",
      "metadata": {
        "id": "ceb71138"
      },
      "outputs": [],
      "source": [
        "# tcount = []\n",
        "# cap = cv2.VideoCapture(video_paths['accident'][0])\n",
        "# total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "# tcount.append(total_frames)\n",
        "# cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dabb347c",
      "metadata": {
        "id": "dabb347c"
      },
      "outputs": [],
      "source": [
        "# print(tcount)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21d97258",
      "metadata": {
        "id": "21d97258"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = r'D:\\FYP_HWU\\NEW_Frames'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d895aee",
      "metadata": {
        "id": "4d895aee"
      },
      "outputs": [],
      "source": [
        "def frameSkipping(video_paths, n):\n",
        "    for action in video_paths.keys():\n",
        "\n",
        "        #Looping through each video of the action\n",
        "        for sequence in range(len(video_paths[action])): #len(video_paths[action])\n",
        "            cap = cv2.VideoCapture(video_paths[action][sequence])\n",
        "\n",
        "            total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)  #getting the total frame count\n",
        "            frames_step = total_frames//n    # getting the number of frames to skip\n",
        "\n",
        "            for frame_num in range(n):\n",
        "                #here, we set the parameter 1 which is the frame number to the frame (i*frames_step)\n",
        "                cap.set(1,frame_num*frames_step)\n",
        "                success,image = cap.read()\n",
        "                #save your image\n",
        "                cv2.imwrite(os.path.join(DATA_PATH, action, str(sequence), 'frame'+ str(frame_num) + '.jpg'), image)\n",
        "\n",
        "            cap.release()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "565ddac3",
      "metadata": {
        "id": "565ddac3"
      },
      "outputs": [],
      "source": [
        "frameSkipping(video_paths, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61a303a8",
      "metadata": {
        "id": "61a303a8"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "911ae365",
      "metadata": {
        "id": "911ae365"
      },
      "source": [
        "By the end of this section, we will folders containing the images frames stored in jpg format for each video of each action."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "944047ec",
      "metadata": {
        "id": "944047ec"
      },
      "source": [
        "## Data Augmentation\n",
        " Using:\n",
        " - Frame Mirroring (Flipping the image horizontally)\n",
        " - Changing contrast, brightness and saturation levels\n",
        " - Rotating\n",
        "\n",
        " Here, we take each video, extract frames and for each frame, apply the filters (which may wither include changing the contrast and brightness of the image frame, mirroring the image or extracting only the keypoints and the edges from the image), and store them as a separate video.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11847f28",
      "metadata": {
        "id": "11847f28"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageEnhance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41f5ca49",
      "metadata": {
        "id": "41f5ca49"
      },
      "outputs": [],
      "source": [
        "def blackAndWhite(image): # takes image as a parameter\n",
        "    # Image color\n",
        "    enhancer = ImageEnhance.Color(image)\n",
        "    new_image = enhancer.enhance(0)\n",
        "\n",
        "    # return np.array(new_image)\n",
        "    return new_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26fa759c",
      "metadata": {
        "id": "26fa759c"
      },
      "outputs": [],
      "source": [
        "def saturation(image): # takes image as a parameter\n",
        "    # Horizontally flipping the image\n",
        "    image = flipImage(image)\n",
        "    # Image color\n",
        "    enhancer = ImageEnhance.Color(image)\n",
        "    new_image = enhancer.enhance(1.5)\n",
        "\n",
        "    # return np.array(new_image)\n",
        "    return new_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b39d16e4",
      "metadata": {
        "id": "b39d16e4"
      },
      "outputs": [],
      "source": [
        "def flipImage(image): # takes image as a parameter\n",
        "    # Converting Image to numpy array\n",
        "    new_image = np.array(image)\n",
        "\n",
        "    # Horizontally flipping the image\n",
        "    image = cv2.flip(new_image, 1)\n",
        "\n",
        "    # Converting numpy aray to image format\n",
        "    image = Image.fromarray(image.astype('uint8'))\n",
        "\n",
        "    # Returning the image in image format\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c715b708",
      "metadata": {
        "id": "c715b708"
      },
      "outputs": [],
      "source": [
        "def rotateImage(image):\n",
        "    image  = image.rotate(-8)  #- or + -> left or right\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "110df0fe",
      "metadata": {
        "id": "110df0fe"
      },
      "outputs": [],
      "source": [
        "# NEW_PATH = r'D:\\FYP_HWU\\New folder'\n",
        "# resize = (224,224)\n",
        "\n",
        "# for frame_num in range (20):\n",
        "#     IMAGE_PATH = os.path.join(DATA_PATH, 'child', '7' , 'frame' + str(frame_num) + '.jpg')\n",
        "\n",
        "#     # Reading the image\n",
        "#     image = cv2.imread(IMAGE_PATH)\n",
        "\n",
        "#     # Resizing the Image\n",
        "#     new_image = resizeFrames(image, resize)\n",
        "\n",
        "#     #Converting numpy array to Image\n",
        "#     image = Image.fromarray(new_image.astype('uint8'))\n",
        "\n",
        "#     # Applying the filters\n",
        "#     new_image = rotateImage(image)\n",
        "\n",
        "#     # Converting Image to numpy array\n",
        "#     new_image = np.array(new_image)\n",
        "\n",
        "#     #Saving the image in the folder created\n",
        "#     cv2.imwrite(os.path.join(NEW_PATH , 'frame'+ str(frame_num) + '.jpg'), new_image)\n",
        "\n",
        "#     # Displaying Image\n",
        "#     cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eb7309f",
      "metadata": {
        "id": "0eb7309f"
      },
      "outputs": [],
      "source": [
        "# Cropping the center of the image (cropping out the extra background margins of the video.)\n",
        "def crop_center_square(frame): # takes image as a parameter\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8427b29c",
      "metadata": {
        "id": "8427b29c"
      },
      "outputs": [],
      "source": [
        "# Function to resize the frames\n",
        "def resizeFrames(new_image, resize): # takes numpy array as parameter\n",
        "    new_image = crop_center_square(new_image)\n",
        "    new_image = cv2.resize(new_image, resize)\n",
        "    return new_image # returns a numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "547ff254",
      "metadata": {
        "id": "547ff254"
      },
      "outputs": [],
      "source": [
        "# Getting the final number of videos under each Action\n",
        "def totalVideoCount(DATA_PATH):\n",
        "    finalVideoCount = {}\n",
        "    for root, dirs, files in os.walk(DATA_PATH):\n",
        "        for folder in dirs:\n",
        "            for root, dirs, files in os.walk(os.path.join(DATA_PATH, folder)):\n",
        "                finalVideoCount[folder] = len(dirs)\n",
        "                break\n",
        "    return finalVideoCount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d99d6836",
      "metadata": {
        "id": "d99d6836"
      },
      "outputs": [],
      "source": [
        "# PATH = r'D:\\FYP_HWU\\Resized_Frames'\n",
        "# videoCount = totalVideoCount(PATH)\n",
        "# print(videoCount)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ed8d486",
      "metadata": {
        "id": "9ed8d486"
      },
      "outputs": [],
      "source": [
        "# IMAGE_PATH = os.path.join(DATA_PATH,'accident', '6', 'frame' + '11' +'.jpg')\n",
        "# print(IMAGE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf0549ed",
      "metadata": {
        "id": "cf0549ed"
      },
      "outputs": [],
      "source": [
        "# resize = (224,224)\n",
        "# img = cv2.imread(IMAGE_PATH)\n",
        "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "# # transposed  = img.rotate(-10)\n",
        "# # new_image = np.array(transposed)\n",
        "# new_image = crop_center_square(img)\n",
        "# new_image = cv2.resize(new_image, resize)\n",
        "# image = Image.fromarray(new_image.astype('uint8'))\n",
        "# new_image = rotateImage(image)\n",
        "# new_image.show()\n",
        "# # image.show()\n",
        "# cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fca1c478",
      "metadata": {
        "id": "fca1c478",
        "outputId": "bd21a380-b287-4f2d-a841-1dfa0adaadcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'accident': 13, 'call': 12, 'child': 9, 'danger': 11, 'follow': 9, 'help': 14, 'man': 12, 'murder': 13, 'police': 10, 'sick': 10, 'woman': 11}\n"
          ]
        }
      ],
      "source": [
        "DATA_PATH = r'D:\\FYP_HWU\\NEW_Frames'\n",
        "VideoCount = totalVideoCount(DATA_PATH)\n",
        "print(VideoCount)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "073adf0b",
      "metadata": {
        "id": "073adf0b"
      },
      "outputs": [],
      "source": [
        "# max_fc = 20 (maximum number of frames extracted per video), variable already initialized earlier\n",
        "\n",
        "# loop through each video (sequence) for each action\n",
        "# create another sequece folder (my_dict[action] + count), where count is incremented with every sequence loop iteration\n",
        "# for loop for i in range(20):\n",
        "# get the image -> concat('frame', str(i))\n",
        "# apply filters\n",
        "# save the image in the new folder created\n",
        "\n",
        "max_fc = 20\n",
        "resize = (224,224)\n",
        "AUG_PATH = r'D:\\FYP_HWU\\NEW_AUG_Frames'\n",
        "DATA_PATH = r'D:\\FYP_HWU\\NEW_Frames'\n",
        "\n",
        "finalVideoCount = totalVideoCount(AUG_PATH)\n",
        "video_count = totalVideoCount(DATA_PATH)\n",
        "\n",
        "#looping through each action\n",
        "for action in video_count.keys():\n",
        "    actionCount = finalVideoCount[action]\n",
        "\n",
        "    #Looping through the count for videos for that action\n",
        "    for sequence in range(video_count[action]):\n",
        "\n",
        "        #creating a folder to store the augmented images\n",
        "        folder_number = actionCount + sequence\n",
        "        if(folder_number < 45):\n",
        "            try:\n",
        "                os.makedirs(os.path.join(AUG_PATH, action, str(folder_number)))\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            for frame_num in range (max_fc):\n",
        "                IMAGE_PATH = os.path.join(AUG_PATH, str(action), str(sequence) , 'frame' + str(frame_num) + '.jpg')\n",
        "\n",
        "                # Reading the image\n",
        "                image = cv2.imread(IMAGE_PATH)\n",
        "\n",
        "                # Resizing the Image\n",
        "#                 new_image = resizeFrames(image, resize)\n",
        "\n",
        "                #Converting numpy array to Image\n",
        "                image = Image.fromarray(image.astype('uint8'))\n",
        "\n",
        "                # Applying the filters\n",
        "#                 new_image = blackAndWhite(image)\n",
        "#                 new_image = flipImage(image)\n",
        "#                 new_image = saturation(image)\n",
        "                new_image = rotateImage(image)\n",
        "\n",
        "                # Converting Image to numpy array\n",
        "                new_image = np.array(new_image)\n",
        "\n",
        "                #Saving the image in the folder created\n",
        "                cv2.imwrite(os.path.join(AUG_PATH , str(action), str(folder_number), 'frame'+ str(frame_num) + '.jpg'), new_image)\n",
        "\n",
        "                # Displaying Image\n",
        "                cv2.destroyAllWindows()\n",
        "\n",
        "        else:\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f661404",
      "metadata": {
        "id": "0f661404",
        "outputId": "58108e35-d237-490e-8622-20f8cf0a6b08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'accident': 45, 'call': 45, 'child': 45, 'danger': 45, 'follow': 45, 'help': 45, 'man': 45, 'murder': 45, 'police': 45, 'sick': 45, 'woman': 45}\n"
          ]
        }
      ],
      "source": [
        "finalVideoCount = totalVideoCount(AUG_PATH)\n",
        "print(finalVideoCount)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26bac943",
      "metadata": {
        "id": "26bac943"
      },
      "source": [
        "## Resizing Images"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86a99f38",
      "metadata": {
        "id": "86a99f38"
      },
      "source": [
        "Resizing the images to 224 x 224 pixel size to feed to ResNet 50 pre trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9e264f5",
      "metadata": {
        "id": "e9e264f5"
      },
      "outputs": [],
      "source": [
        "# Cropping the center of the image (cropping out the extra background margins of the video.)\n",
        "def crop_center_square(frame): # takes image as a parameter\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44d53127",
      "metadata": {
        "id": "44d53127"
      },
      "outputs": [],
      "source": [
        "# Function to resize the frames\n",
        "def resizeFrames(new_image, resize): # takes numpy array as parameter\n",
        "    new_image = crop_center_square(new_image)\n",
        "    new_image = cv2.resize(new_image, resize)\n",
        "    return new_image # returns a numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7d1cb57",
      "metadata": {
        "id": "b7d1cb57"
      },
      "outputs": [],
      "source": [
        "max_fc = 20\n",
        "resize = (224,224)\n",
        "AUG_PATH = r'D:\\FYP_HWU\\NEW_AUG_Frames'\n",
        "DATA_PATH = r'D:\\FYP_HWU\\NEW_Frames'\n",
        "\n",
        "videoCount = totalVideoCount(DATA_PATH) #getting a video count from original frame dataset\n",
        "\n",
        "#looping through each action\n",
        "for action in videoCount.keys():\n",
        "\n",
        "    #Looping through the count for videos for that action\n",
        "    for sequence in range(videoCount[action]):\n",
        "\n",
        "        #creating a folder in AUG frames folder\n",
        "        try:\n",
        "            os.makedirs(os.path.join(AUG_PATH, action, str(sequence)))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # iterating through each frame in the original frame dataset\n",
        "        for frame_num in range (max_fc):\n",
        "            IMAGE_PATH = os.path.join(DATA_PATH, str(action), str(sequence) , 'frame' + str(frame_num) + '.jpg')\n",
        "\n",
        "            # Reading the image\n",
        "            image = cv2.imread(IMAGE_PATH)\n",
        "\n",
        "            new_image = resizeFrames(image, resize)\n",
        "\n",
        "            #Saving the image in the folder created\n",
        "            cv2.imwrite(os.path.join(AUG_PATH, str(action), str(sequence), 'frame' + str(frame_num) + '.jpg'), new_image)\n",
        "\n",
        "            # Displaying Image\n",
        "            cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "687f20f4",
      "metadata": {
        "id": "687f20f4"
      },
      "source": [
        "## Keypoint Extraction using MediaPipe Holistics\n",
        "Applying MediaPipe Keypoint Landmarks to the extracted frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2b61ee5",
      "metadata": {
        "id": "b2b61ee5"
      },
      "outputs": [],
      "source": [
        "mp_holistic = mp.solutions.holistic #Holistic model (use for detections)\n",
        "mp_drawing = mp.solutions.drawing_utils #Drawing Utilities\n",
        "drawing_spec = mp_drawing.DrawingSpec(thickness = 1, circle_radius=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ca65d26",
      "metadata": {
        "id": "8ca65d26"
      },
      "outputs": [],
      "source": [
        "# # max_fc = 20\n",
        "# AUG_PATH = r'D:\\FYP_HWU\\NEW_AUG_Frames\\accident\\0\\frame12.jpg'\n",
        "\n",
        "# # Reading the image\n",
        "# image = cv2.imread(AUG_PATH)\n",
        "\n",
        "# # Making detection\n",
        "# with mp_holistic.Holistic(min_detection_confidence = 0.5, min_tracking_confidence = 0.5) as holistic:\n",
        "#     image, result = mediapipeHolistics(image, holistic)\n",
        "\n",
        "# #Darwing landmarks on frames\n",
        "# draw_landmarks(image,result)\n",
        "\n",
        "# image = Image.fromarray(image.astype('uint8'))\n",
        "# image.show()\n",
        "# # Displaying Image\n",
        "# cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a4039ce",
      "metadata": {
        "id": "8a4039ce"
      },
      "outputs": [],
      "source": [
        "#Capturing landmarks\n",
        "def mediapipeHolistics(image, model):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #color conversion -> BGR to RGB\n",
        "    image.flags.writeable = False\n",
        "    results = model.process(image) # Making Prediction\n",
        "    image.flags.writeable = True\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) #color conversion -> RGB to BGR\n",
        "    return image, results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7dbe39a",
      "metadata": {
        "id": "f7dbe39a"
      },
      "outputs": [],
      "source": [
        "#Visualize landmarks, connecting the landmarks on the image (drawing only pose and had landmarks)\n",
        "def draw_landmarks(image, results):\n",
        "    mp_drawing.draw_landmarks(image = image,\n",
        "                              landmark_list = results.pose_landmarks,\n",
        "                              connections = mp_holistic.POSE_CONNECTIONS,\n",
        "                              landmark_drawing_spec = drawing_spec,\n",
        "                              connection_drawing_spec = drawing_spec)\n",
        "    mp_drawing.draw_landmarks(image = image,\n",
        "                              landmark_list = results.left_hand_landmarks,\n",
        "                              connections = mp_holistic.HAND_CONNECTIONS,\n",
        "                              landmark_drawing_spec = drawing_spec,\n",
        "                              connection_drawing_spec = drawing_spec)\n",
        "    mp_drawing.draw_landmarks(image = image,\n",
        "                              landmark_list = results.right_hand_landmarks,\n",
        "                              connections = mp_holistic.HAND_CONNECTIONS,\n",
        "                              landmark_drawing_spec = drawing_spec,\n",
        "                              connection_drawing_spec = drawing_spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0907fea",
      "metadata": {
        "id": "d0907fea"
      },
      "outputs": [],
      "source": [
        "max_fc = 20\n",
        "AUG_PATH = r'D:\\FYP_HWU\\NEW_AUG_Frames'\n",
        "FRAMES_PATH = r'D:\\FYP_HWU\\NEW_MP_Frames'\n",
        "\n",
        "finalVideoCount = totalVideoCount(AUG_PATH)\n",
        "\n",
        "#looping through each action\n",
        "for action in finalVideoCount.keys():\n",
        "\n",
        "    #Looping through the count for videos for that action\n",
        "    for sequence in range(finalVideoCount[action]):\n",
        "\n",
        "        # Creating folders to store frames and extracted landmarks\n",
        "        try:\n",
        "            os.makedirs(os.path.join(FRAMES_PATH, action, str(sequence)))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        with mp_holistic.Holistic(min_detection_confidence = 0.5, min_tracking_confidence = 0.5) as holistic:\n",
        "            for frame_num in range (max_fc):\n",
        "\n",
        "                # Getting the extracted frame from the folder\n",
        "                IMAGE_PATH = os.path.join(AUG_PATH, str(action), str(sequence) , 'frame' + str(frame_num) + '.jpg')\n",
        "\n",
        "                # Reading the image\n",
        "                image = cv2.imread(IMAGE_PATH)\n",
        "\n",
        "                # Making detection\n",
        "                image, result = mediapipeHolistics(image, holistic)\n",
        "\n",
        "                #Darwing landmarks on frames\n",
        "                draw_landmarks(image,result)\n",
        "\n",
        "#                 image = Image.fromarray(image.astype('uint8'))\n",
        "\n",
        "                #Saving the image in the folder created\n",
        "                cv2.imwrite(os.path.join(FRAMES_PATH , str(action), str(sequence), 'frame'+ str(frame_num) + '.jpg'), image)\n",
        "\n",
        "                # Displaying Image\n",
        "                cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd21b136",
      "metadata": {
        "id": "bd21b136"
      },
      "source": [
        "# Creating the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fb1b3b8",
      "metadata": {
        "id": "7fb1b3b8"
      },
      "source": [
        "### Visualizing dataset frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u7HxDaYT9iBd",
      "metadata": {
        "id": "u7HxDaYT9iBd"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageEnhance\n",
        "from IPython.display import Image\n",
        "DATA_PATH = r'NEW_MP_Frames'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74910e0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "74910e0f",
        "outputId": "4e2141b7-8473-4fc8-9ea9-07729d971b6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ACTION: Man    Video: 0     Frame: 22\n"
          ]
        },
        {
          "data": {
            "image/jpeg": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# man (video 0, frame 22)\n",
        "print(\"ACTION: Man    Video: 0     Frame: 22\")\n",
        "display(Image(filename=\"{}/man/0/frame15.jpg\". format(DATA_PATH)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38f3d374",
      "metadata": {
        "id": "38f3d374"
      },
      "source": [
        "## Creating Labels and Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0ec1f3f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip3 install tensorflow --user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "304ab091",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp39-cp39-win_amd64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.5-cp39-cp39-win_amd64.whl (14.7 MB)\n",
            "   ---------------------------------------- 0.0/14.7 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.3/14.7 MB 9.9 MB/s eta 0:00:02\n",
            "   -- ------------------------------------- 0.9/14.7 MB 11.9 MB/s eta 0:00:02\n",
            "   -- ------------------------------------- 1.0/14.7 MB 11.0 MB/s eta 0:00:02\n",
            "   -- ------------------------------------- 1.0/14.7 MB 11.0 MB/s eta 0:00:02\n",
            "   -- ------------------------------------- 1.0/14.7 MB 11.0 MB/s eta 0:00:02\n",
            "   --- ------------------------------------ 1.3/14.7 MB 5.0 MB/s eta 0:00:03\n",
            "   ----- ---------------------------------- 2.1/14.7 MB 6.7 MB/s eta 0:00:02\n",
            "   ----- ---------------------------------- 2.1/14.7 MB 6.7 MB/s eta 0:00:02\n",
            "   ----- ---------------------------------- 2.1/14.7 MB 6.7 MB/s eta 0:00:02\n",
            "   ----- ---------------------------------- 2.1/14.7 MB 6.7 MB/s eta 0:00:02\n",
            "   -------- ------------------------------- 3.0/14.7 MB 5.9 MB/s eta 0:00:02\n",
            "   -------- ------------------------------- 3.1/14.7 MB 6.3 MB/s eta 0:00:02\n",
            "   -------- ------------------------------- 3.1/14.7 MB 6.3 MB/s eta 0:00:02\n",
            "   -------- ------------------------------- 3.1/14.7 MB 6.3 MB/s eta 0:00:02\n",
            "   --------- ------------------------------ 3.4/14.7 MB 4.9 MB/s eta 0:00:03\n",
            "   ----------- ---------------------------- 4.2/14.7 MB 5.9 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 4.2/14.7 MB 5.9 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 4.2/14.7 MB 5.9 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 4.2/14.7 MB 5.9 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 5.2/14.7 MB 5.8 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 5.2/14.7 MB 5.8 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 5.2/14.7 MB 5.8 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 5.2/14.7 MB 5.8 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 6.9/14.7 MB 6.2 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 8.4/14.7 MB 7.3 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 8.4/14.7 MB 7.3 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 8.4/14.7 MB 7.3 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 8.4/14.7 MB 7.3 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 9.4/14.7 MB 7.2 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 9.4/14.7 MB 7.2 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 9.4/14.7 MB 7.2 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 9.4/14.7 MB 7.2 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 10.5/14.7 MB 7.0 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 10.5/14.7 MB 7.0 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 10.5/14.7 MB 7.0 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 10.5/14.7 MB 7.0 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 12.1/14.7 MB 7.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 14.7/14.7 MB 11.9 MB/s eta 0:00:00\n",
            "Installing collected packages: numpy\n",
            "Successfully installed numpy-1.23.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: The script f2py.exe is installed in 'C:\\Users\\dr2007\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires clang~=5.0, which is not installed.\n",
            "tensorboard 2.6.0 requires google-auth<2,>=1.6.3, but you have google-auth 2.22.0 which is incompatible.\n",
            "tensorflow 2.6.0 requires absl-py~=0.10, but you have absl-py 1.4.0 which is incompatible.\n",
            "tensorflow 2.6.0 requires flatbuffers~=1.12, but you have flatbuffers 20210226132247 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "# !pip3 uninstall numpy==1.20.1\n",
        "# !pip3 install numpy==1.23.5 --user\n",
        "# import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "413ea077",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.23.5'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np \n",
        "np.__version__  #'1.23.5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a29f1304",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4d4a2a96",
      "metadata": {
        "id": "4d4a2a96"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "03592f2b",
      "metadata": {
        "id": "03592f2b"
      },
      "outputs": [],
      "source": [
        "# # Splitting data in 80:10:10 train:validation:test ratio\n",
        "# def trainTestSplit(X,y):\n",
        "#     x_train, x_temp, y_train, y_temp= train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "#     x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size = 0.5, random_state=42)\n",
        "#     return x_train, y_train, x_val, y_val, x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f12045ff",
      "metadata": {
        "id": "f12045ff"
      },
      "outputs": [],
      "source": [
        "def trainTestSplit(X,y):\n",
        "    x_train, x_val, y_train, y_val= train_test_split(X, y, test_size=0.05, random_state=42)\n",
        "    return x_train, y_train, x_val, y_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b274e54d",
      "metadata": {
        "id": "b274e54d"
      },
      "outputs": [],
      "source": [
        "# DATA_PATH = r'NEW_MP_Frames'\n",
        "# DATA_PATH = r'D:\\FYP_HWU\\NEW_MP_Frames'\n",
        "DATA_PATH = r'C:\\Users\\dr2007\\Documents\\FYP_DATA\\NEW_MP_Frames'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "FTXm-CUpEi36",
      "metadata": {
        "id": "FTXm-CUpEi36"
      },
      "outputs": [],
      "source": [
        "# Getting the final number of videos under each Action\n",
        "def totalVideoCount(DATA_PATH):\n",
        "    finalVideoCount = {}\n",
        "    for root, dirs, files in os.walk(DATA_PATH):\n",
        "        for folder in dirs:\n",
        "            for root, dirs, files in os.walk(os.path.join(DATA_PATH, folder)):\n",
        "                finalVideoCount[folder] = len(dirs)\n",
        "                break\n",
        "    return finalVideoCount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "641b9556",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "641b9556",
        "outputId": "402ed957-9c2f-4d47-9f6c-6b97bbcb7277"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'police': 45, 'follow': 45, 'child': 45, 'woman': 45}\n"
          ]
        }
      ],
      "source": [
        "# Creating subset to to test whether the model works fine\n",
        "total_video_count = totalVideoCount(DATA_PATH)\n",
        "temp_list = ['police', 'follow', 'child', 'woman']\n",
        "subset_video_count = {}\n",
        "for temp in temp_list:\n",
        "    subset_video_count[temp] = total_video_count[temp]\n",
        "\n",
        "print(subset_video_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "839e982b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'accident': 45, 'call': 45, 'child': 45, 'danger': 45, 'follow': 45, 'help': 45, 'man': 45, 'murder': 45, 'police': 45, 'sick': 45, 'woman': 45}\n"
          ]
        }
      ],
      "source": [
        "# total_video_count = totalVideoCount(DATA_PATH)\n",
        "print(total_video_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "47d0ffa6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'accident': 45, 'call': 45, 'child': 45, 'danger': 45, 'follow': 45, 'help': 45, 'man': 45, 'murder': 45, 'police': 45, 'sick': 45, 'woman': 45}\n"
          ]
        }
      ],
      "source": [
        "print(total_video_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f3609ab",
      "metadata": {
        "id": "4f3609ab"
      },
      "outputs": [],
      "source": [
        "# subset_video_count = {'police': 40, 'follow': 36}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f88d74c3",
      "metadata": {
        "id": "f88d74c3"
      },
      "outputs": [],
      "source": [
        "# Setting numeric labels for non numeric action category values\n",
        "# label_map = {label:num for num, label in enumerate(total_video_count.keys())} # all classes\n",
        "label_map = {label:num for num, label in enumerate(subset_video_count.keys())} #subset of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "29263b59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29263b59",
        "outputId": "fc7ada33-4fd6-4557-f654-9f2191c61b4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'police': 0, 'follow': 1, 'child': 2, 'woman': 3}\n"
          ]
        }
      ],
      "source": [
        "print(label_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aK5lyRKAB6c",
      "metadata": {
        "id": "7aK5lyRKAB6c"
      },
      "source": [
        "### Preparing Data with 'Mediapipe Landmarks' stored as numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "798440c4",
      "metadata": {
        "collapsed": true,
        "id": "798440c4"
      },
      "outputs": [],
      "source": [
        "# SUBSET CLASSES\n",
        "\n",
        "#features = non target columns    labels = target columns\n",
        "\n",
        "max_fc = 20\n",
        "features, labels = [], []\n",
        "\n",
        "# Iterating through each action\n",
        "for action in subset_video_count.keys():\n",
        "\n",
        "    # Iterting through each video in the action\n",
        "    for sequence in range(subset_video_count[action]):\n",
        "\n",
        "        # Declaring a list to store the frames of each video\n",
        "        frames = []\n",
        "\n",
        "        # Iterating through each landmark numpy array\n",
        "        for frame_num in range(max_fc):\n",
        "\n",
        "            # Declaring directory of the keypoints\n",
        "            IMAGE_PATH = os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num))\n",
        "\n",
        "            # Loading the numpy array\n",
        "            res = np.load(IMAGE_PATH)\n",
        "\n",
        "            # Appending to the list\n",
        "            frames.append(res)\n",
        "\n",
        "        # Adding to the dataset\n",
        "        features.append(frames)\n",
        "        labels.append(label_map[action])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b033ce87",
      "metadata": {
        "id": "b033ce87"
      },
      "outputs": [],
      "source": [
        "# ALL CLASSES\n",
        "\n",
        "max_fc = 20\n",
        "features, labels = [], []\n",
        "# Iterating through each action\n",
        "for action in subset_video_count.keys():\n",
        "\n",
        "    # Iterting through each video in the action\n",
        "    for sequence in range(subset_video_count[action]):\n",
        "\n",
        "        # Declaring a list to store the frames of each video\n",
        "        frames = []\n",
        "\n",
        "        # Iterating through each landmark numpy array\n",
        "        for frame_num in range(max_fc):\n",
        "\n",
        "            # Declaring directory of the keypoints\n",
        "            IMAGE_PATH = os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num))\n",
        "\n",
        "            # Loading the numpy array\n",
        "            res = np.load(IMAGE_PATH)\n",
        "\n",
        "            # Appending to the list\n",
        "            frames.append(res)\n",
        "\n",
        "        # Adding to the dataset\n",
        "        features.append(frames)\n",
        "        labels.append(label_map[action])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44cc4f53",
      "metadata": {
        "id": "44cc4f53"
      },
      "outputs": [],
      "source": [
        "# np.array(features).shape\n",
        "X = np.array(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62390ca3",
      "metadata": {
        "id": "62390ca3"
      },
      "outputs": [],
      "source": [
        "# np.array(labels).shape\n",
        "# The below code will convert the target class to this format: [1,0,0], [0,1,0], [0,0,1]\n",
        "y = to_categorical(labels).astype(int)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6512f0c",
      "metadata": {
        "id": "a6512f0c"
      },
      "outputs": [],
      "source": [
        "# Splitting into Train, Validation and Test\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = trainTestSplit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "163062cb",
      "metadata": {
        "id": "163062cb"
      },
      "source": [
        "### Preparing Data with Extracted Frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1a52b3c",
      "metadata": {
        "id": "c1a52b3c"
      },
      "outputs": [],
      "source": [
        "# # Home Computer Paths\n",
        "# IMAGE_PATH = r'C:\\Users\\revan\\Downloads\\frame101.jpg'\n",
        "# DATA_PATH = r'C:\\Users\\revan\\Downloads\\BOOK.mp4'\n",
        "# IM_PATH = r'C:\\Users\\revan\\Downloads\\frame101.npy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0557ab0",
      "metadata": {
        "id": "b0557ab0"
      },
      "outputs": [],
      "source": [
        "# # cap = cv2.VideoCapture(DATA_PATH)\n",
        "# # # DATAPATH = os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num))\n",
        "# frame = cv2.imread(IMAGE_PATH)\n",
        "# # frame = frame[:, :, [2, 1, 0]]\n",
        "# image = Image.fromarray(frame.astype('uint8'))\n",
        "# # new_image := np.array(image)\n",
        "# # cv2.imwrite(IM_PATH,new_image)\n",
        "# image.show()\n",
        "# cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b580ea50",
      "metadata": {
        "id": "b580ea50"
      },
      "outputs": [],
      "source": [
        "# get the video count\n",
        "# video_count = {'accident': 40, 'call': 40, 'child': 36, 'danger': 40, 'follow': 36, 'help': 40, 'man': 40, 'murder': 40, 'police': 40, 'sick': 40, 'woman': 40}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dea605fa",
      "metadata": {
        "id": "dea605fa"
      },
      "outputs": [],
      "source": [
        "# University Computer Paths\n",
        "\n",
        "# IMAGE_PATH = r'C:\\Users\\dr2007\\Documents\\FYP_HWU\\Frames\\accident\\0\\frame0.jpg'\n",
        "# DATA_PATH = r'C:\\Users\\dr2007\\Documents\\FYP_HWU\\Aug_Frames'\n",
        "# DATA_PATH = r'C:\\Users\\dr2007\\Documents\\FYP_HWU\\MP_Frames'\n",
        "# DATA_PATH = r'NEW_MP_Frames'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "12974db6",
      "metadata": {
        "id": "12974db6"
      },
      "outputs": [],
      "source": [
        "def frameEnhance(frame):\n",
        "    # Converting BGR -> RGB\n",
        "    frame = frame[:, :, [2, 1, 0]]\n",
        "    # Normalize the pixel values\n",
        "    frame = frame / 255.0\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3900ef4b",
      "metadata": {
        "id": "3900ef4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action accident done\n",
            "Action call done\n",
            "Action child done\n",
            "Action danger done\n",
            "Action follow done\n",
            "Action help done\n",
            "Action man done\n",
            "Action murder done\n",
            "Action police done\n",
            "Action sick done\n",
            "Action woman done\n"
          ]
        }
      ],
      "source": [
        "# For ALL the classes\n",
        "max_fc = 20\n",
        "videoFrames=[]\n",
        "videolabels=[]\n",
        "\n",
        "# Iterating through each action\n",
        "for action in total_video_count.keys():\n",
        "\n",
        "    # Iterting through each video in the action\n",
        "    for sequence in range(total_video_count[action]):\n",
        "\n",
        "        # Declaring a list to store the frames of each video\n",
        "        frames = []\n",
        "\n",
        "        # Iterating through each frame\n",
        "        for frame_num in range(max_fc):\n",
        "\n",
        "            # Loading the image frame\n",
        "            frame = cv2.imread(os.path.join(DATA_PATH, action, str(sequence), \"frame{}\".format(frame_num) + \".jpg\"))\n",
        "            frame = frameEnhance(frame)\n",
        "\n",
        "            # Appending to the list\n",
        "            frames.append(frame)\n",
        "\n",
        "        # Adding to the dataset\n",
        "        videoFrames.append(frames)\n",
        "        videolabels.append(label_map[action])\n",
        "\n",
        "    print(\"Action {} done\".format(action))\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e369980",
      "metadata": {
        "id": "3e369980"
      },
      "outputs": [],
      "source": [
        "# DATA_PATH = r'C:\\Users\\dr2007\\Documents\\FYP_HWU\\Resized_Frames'\n",
        "# DATA_PATH = r'D:\\FYP_HWU\\MP_Frames'\n",
        "# DATA_PATH = r'NEW_MP_Frames'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "4511c9a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4511c9a3",
        "outputId": "bc9a08d8-e76d-457d-bf45-a560aa61ffb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dr2007\\Documents\\FYP_DATA\\NEW_MP_Frames\n"
          ]
        }
      ],
      "source": [
        "# print(total_video_count)\n",
        "print(DATA_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bde04ed0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bde04ed0",
        "outputId": "e38cf799-3295-4099-af82-33ff9b279c06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action police done\n",
            "Action follow done\n",
            "Action child done\n",
            "Action woman done\n"
          ]
        }
      ],
      "source": [
        "# For subset of the classes (3 classes) [child, follow, police]\n",
        "max_fc = 20\n",
        "videoFrames=[]\n",
        "videolabels=[]\n",
        "\n",
        "# Iterating through each action\n",
        "for action in subset_video_count.keys():\n",
        "\n",
        "    # Iterting through each video in the action\n",
        "    for sequence in range(subset_video_count[action]):\n",
        "\n",
        "        # Declaring a list to store the frames of each video\n",
        "        frames = []\n",
        "\n",
        "        # Iterating through each frame\n",
        "        for frame_num in range(max_fc):\n",
        "\n",
        "            # Loading the image frame\n",
        "            frame = cv2.imread(os.path.join(DATA_PATH, action, str(sequence), \"frame{}\".format(frame_num) + \".jpg\"))\n",
        "            frame = frameEnhance(frame)\n",
        "\n",
        "            # Appending to the list\n",
        "            frames.append(frame)\n",
        "\n",
        "        # Adding to the dataset\n",
        "        videoFrames.append(frames)\n",
        "        videolabels.append(label_map[action])\n",
        "\n",
        "    print(\"Action {} done\".format(action))\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0e83168f",
      "metadata": {
        "id": "0e83168f"
      },
      "outputs": [],
      "source": [
        "# np.array(videoFrames).shape\n",
        "X = np.array(videoFrames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "26505e20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26505e20",
        "outputId": "7540d968-4e53-4086-f14a-7a5717db6bab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "180\n"
          ]
        }
      ],
      "source": [
        "print(len(videoFrames))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "03dbe16b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03dbe16b",
        "outputId": "dc08f0de-dea0-4e7c-c42c-ca9809edafed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(180, 20, 224, 224, 3)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "54813e46",
      "metadata": {
        "id": "54813e46"
      },
      "outputs": [],
      "source": [
        "# np.array(videolabels).shape\n",
        "# The below code will convert the target class to this format: [1,0,0], [0,1,0], [0,0,1]\n",
        "y = to_categorical(videolabels).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "95a7730a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95a7730a",
        "outputId": "0477ac00-8460-417b-c905-19004a43fb37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(180, 4)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hK2LJOZY_e1T",
      "metadata": {
        "id": "hK2LJOZY_e1T"
      },
      "outputs": [],
      "source": [
        "# np.save('X_data.npy', X)\n",
        "# np.save('y_data.npy', y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e3062780",
      "metadata": {
        "id": "e3062780"
      },
      "outputs": [],
      "source": [
        "# Splitting into Train, Validation and Test\n",
        "# X_train, y_train, X_val, y_val, X_test, y_test = trainTestSplit(X, y)\n",
        "X_train, y_train, X_val, y_val = trainTestSplit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "7eae675e",
      "metadata": {
        "id": "7eae675e",
        "outputId": "4f454d01-3ad9-439a-d5a1-b7c5a84adcf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(171, 20, 224, 224, 3)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8de003a7",
      "metadata": {
        "id": "8de003a7"
      },
      "outputs": [],
      "source": [
        "# X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "a5860b87",
      "metadata": {
        "id": "a5860b87",
        "outputId": "cabc2f52-8e9a-4345-e212-541d1393348b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(15, 20, 224, 224, 3)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f8b2e1b",
      "metadata": {
        "id": "1f8b2e1b"
      },
      "source": [
        "# Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef5b3c77",
      "metadata": {
        "id": "ef5b3c77"
      },
      "source": [
        "## Building model for MediaPipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0a4d4d9",
      "metadata": {
        "id": "c0a4d4d9"
      },
      "outputs": [],
      "source": [
        "# tensorflow\n",
        "# import tensorflow.keras as keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# model / neural network\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d9e9e36",
      "metadata": {
        "id": "7d9e9e36"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a763e40f",
      "metadata": {
        "id": "a763e40f"
      },
      "outputs": [],
      "source": [
        "num_classes = 11\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "# frames = 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1caebf3f",
      "metadata": {
        "id": "1caebf3f"
      },
      "outputs": [],
      "source": [
        "log_dir = r'D:\\FYP_HWU\\Logs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fa044f5",
      "metadata": {
        "id": "3fa044f5"
      },
      "outputs": [],
      "source": [
        "os.makedirs(log_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "283299f0",
      "metadata": {
        "id": "283299f0"
      },
      "source": [
        "RESNET 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecf297a9",
      "metadata": {
        "id": "ecf297a9",
        "outputId": "5764abf6-7677-43f3-8036-a93228309e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logs\\ckpt.RES50Bi_model.h5\n"
          ]
        }
      ],
      "source": [
        "# folder_path = os.path.join(log_dir,\"ckpt.RES50Bi_model.h5\")\n",
        "folder_path = os.path.join(log_dir,\"ckpt.CNNBi_model.keras\")\n",
        "print(folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e8484ba",
      "metadata": {
        "id": "9e8484ba"
      },
      "outputs": [],
      "source": [
        "# defining a function to save the weights of best model\n",
        "# checkpoint = ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "folder_path = os.path.join(log_dir,\"ckpt.RES50Bi_model.keras\")\n",
        "print(folder_path)\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "        folder_path, save_best_only=True, monitor = \"val_accuracy\", mode = \"max\"\n",
        "    )\n",
        "\n",
        "# earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min', restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70157764",
      "metadata": {
        "id": "70157764"
      },
      "outputs": [],
      "source": [
        "model = ResNet50(include_top=False, weights='imagenet', input_shape=(224,224,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "434d805c",
      "metadata": {
        "id": "434d805c"
      },
      "outputs": [],
      "source": [
        "#defining the model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(actions.shape[0], activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ee21ee1",
      "metadata": {
        "id": "5ee21ee1"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', metrics=['categorical_accuracy'], loss = 'categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78bef577",
      "metadata": {
        "id": "78bef577"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train, epochs=50, callbacks = [checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59994c6e",
      "metadata": {
        "id": "59994c6e"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12cf39a7",
      "metadata": {
        "id": "12cf39a7"
      },
      "outputs": [],
      "source": [
        "# model.save(\"resnet50.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d4b1a2d",
      "metadata": {
        "id": "6d4b1a2d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2d38d74",
      "metadata": {
        "id": "b2d38d74"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70d5d4ce",
      "metadata": {
        "id": "70d5d4ce"
      },
      "outputs": [],
      "source": [
        "# # build the entire model\n",
        "# x = resnet_50.output\n",
        "# x = layers.GlobalAveragePooling2D()(x)\n",
        "# x = layers.Dense(512, activation='relu')(x)\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "# x = layers.Dense(256, activation='relu')(x)\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "# x = layers.Dense(128, activation='relu')(x)\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "# x = layers.Dense(64, activation='relu')(x)\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "# predictions = layers.Dense(5, activation='softmax')(x)\n",
        "# model = Model(inputs = resnet_50.input, outputs = predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b51bd75",
      "metadata": {
        "id": "7b51bd75"
      },
      "source": [
        "BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aae9dd3f",
      "metadata": {
        "id": "aae9dd3f"
      },
      "outputs": [],
      "source": [
        "# model = Sequential()\n",
        "# model.add(Embedding(noClasses, batch_size, input_length=maxlen))\n",
        "# model.add(Bidirectional(LSTM(64)))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7859fb9",
      "metadata": {
        "id": "e7859fb9"
      },
      "outputs": [],
      "source": [
        "#  history=model.fit(x_train, y_train,\n",
        "#            batch_size=batch_size,\n",
        "#            epochs=20,\n",
        "#            validation_data=[x_test, y_test])\n",
        "#  print(history.history['loss'])\n",
        "#  print(history.history['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25a57dd0",
      "metadata": {
        "id": "25a57dd0"
      },
      "outputs": [],
      "source": [
        "# Creating the model\n",
        "# model = tf.keras.Sequential([\n",
        "#     encoder,\n",
        "#     tf.keras.layers.Embedding(11, 64, mask_zero=True),\n",
        "#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
        "#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "#     tf.keras.layers.Dense(64, activation='relu'),\n",
        "#     tf.keras.layers.Dense(1)\n",
        "# ])\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(\n",
        "#     loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "#     optimizer=tf.keras.optimizers.Adam(),\n",
        "#     metrics=['accuracy']\n",
        "# )\n",
        "\n",
        "\n",
        "# # Training the model and validating it on test set\n",
        "# history = model.fit(\n",
        "#     train_dataset,\n",
        "#     epochs=5,\n",
        "#     validation_data=test_dataset,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d571e00",
      "metadata": {
        "id": "7d571e00"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(noClasses, batch_size, input_length=maxlen))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True, activation = 'relu')))\n",
        "model.add(Bidirectional(LSTM(32, return_sequences=False, activation = 'relu')))\n",
        "# model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(actions.shape[0], activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "134b496e",
      "metadata": {
        "id": "134b496e"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', metrics=['categorical_accuracy'], loss = 'categorical_corssentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16c1ba72",
      "metadata": {
        "id": "16c1ba72"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train, epochs=20, callbacks = [checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1919f7e0",
      "metadata": {
        "id": "1919f7e0"
      },
      "outputs": [],
      "source": [
        "model.save(\"bilstm.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6ae594e",
      "metadata": {
        "id": "c6ae594e"
      },
      "outputs": [],
      "source": [
        "# Summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be38d94c",
      "metadata": {
        "id": "be38d94c"
      },
      "outputs": [],
      "source": [
        "# %pip install --user tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73ea75b4",
      "metadata": {
        "collapsed": true,
        "id": "73ea75b4"
      },
      "outputs": [],
      "source": [
        "# !pip3 install --user numpy==1.22.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cd7e79b",
      "metadata": {
        "id": "9cd7e79b"
      },
      "source": [
        "### #-------------------------------------------------------------#"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74368859",
      "metadata": {
        "id": "74368859"
      },
      "source": [
        "RESNET 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3c1d361",
      "metadata": {
        "id": "c3c1d361"
      },
      "outputs": [],
      "source": [
        "# # ResNet50 model\n",
        "# resnet_50 = ResNet50(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
        "# for layer in resnet_50.layers:\n",
        "#     layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f1a59cf",
      "metadata": {
        "id": "6f1a59cf"
      },
      "outputs": [],
      "source": [
        "# # build the entire model\n",
        "# x = resnet_50.output\n",
        "# x = layers.GlobalAveragePooling2D()(x)\n",
        "# x = layers.Dense(512, activation='relu')(x)\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "# x = layers.Dense(256, activation='relu')(x)\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "# x = layers.Dense(128, activation='relu')(x)\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "# x = layers.Dense(64, activation='relu')(x)\n",
        "# x = layers.Dropout(0.5)(x)\n",
        "# predictions = layers.Dense(5, activation='softmax')(x)\n",
        "# model = Model(inputs = resnet_50.input, outputs = predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5d0b438",
      "metadata": {
        "id": "c5d0b438"
      },
      "source": [
        "3D CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c5949e7",
      "metadata": {
        "id": "7c5949e7"
      },
      "outputs": [],
      "source": [
        "# model.compile(Adam(0.001),'categorical_crossentropy',['accuracy'])\n",
        "# model.fit(xtrain,ytrain,epochs=200,batch_size=32,verbose=1,validation_data=(xtest,ytest),callbacks=[EarlyStopping(patience=15)])\n",
        "# Testing the 3D-CNN\n",
        "# _, acc = model.evaluate(xtrain, ytrain)\n",
        "# print('training accuracy:', str(round(acc*100, 2))+'%')\n",
        "# _, acc = model.evaluate(xtest, ytest)\n",
        "# print('testing accuracy:', str(round(acc*100, 2))+'%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30fe6be3",
      "metadata": {
        "id": "30fe6be3"
      },
      "source": [
        "TRANSFORMER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15a7f7b3",
      "metadata": {
        "id": "15a7f7b3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51f91f7b",
      "metadata": {
        "id": "51f91f7b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "77e5d787",
      "metadata": {
        "id": "77e5d787"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "258f25c4",
      "metadata": {
        "id": "258f25c4"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "4d55ffb8",
      "metadata": {
        "id": "4d55ffb8"
      },
      "outputs": [],
      "source": [
        "log_dir = r'C:\\Users\\dr2007\\Documents\\FYP_DATA\\Logs'\n",
        "# os.makedirs('Logs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "b7a3f046",
      "metadata": {
        "id": "b7a3f046"
      },
      "outputs": [],
      "source": [
        "# defining a function to save the weights of best model\n",
        "# log_dir = r'Logs'\n",
        "folder_path = os.path.join(log_dir,\"ckpt.Res50BiLSTM_sub1.keras\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "        folder_path, save_best_only=True, monitor = \"val_accuracy\", mode = \"max\"\n",
        "    )\n",
        "\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min', restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0767fa42",
      "metadata": {
        "id": "0767fa42"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, TimeDistributed, Dropout, LSTM, Bidirectional, Input, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPool2D, Reshape, Flatten,Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "07976b6a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.15.0'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# tf. __version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "779a45a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip3 install tensorflow --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n_GlfvUOI1JW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_GlfvUOI1JW",
        "outputId": "12ab986a-40fe-41b8-8a27-959eaa0e635a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b6e189ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6e189ca",
        "outputId": "99e92dbe-6bbc-4517-a26c-9b49a570b2f4"
      },
      "outputs": [],
      "source": [
        "# actions = len(total_video_count.keys())\n",
        "# print(actions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a1d3988",
      "metadata": {},
      "source": [
        "### ResNet50 + BiLSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d957cb8",
      "metadata": {
        "id": "5d957cb8"
      },
      "source": [
        "RESNET 50 + BiLSTM (224 x 224 images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5eb139c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5eb139c",
        "outputId": "8163566d-c4b2-444a-a701-67fe039bacbd"
      },
      "outputs": [],
      "source": [
        "# Assuming you have a ResNet50 model loaded with pre-trained weights\n",
        "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "resnet_model.trainable = False  # Freeze the weights of the ResNet50 model\n",
        "\n",
        "noActions = len(subset_video_count.keys())\n",
        "\n",
        "# Define the BiLSTM model\n",
        "bilstm_model = Sequential()\n",
        "# bilstm_model.add(Bidirectional(LSTM(64, return_sequences=True, activation = 'relu', input_shape = (60,2048))))\n",
        "bilstm_model.add(Bidirectional(LSTM(64, return_sequences=True, activation='relu'), input_shape=(20, 2048)))\n",
        "bilstm_model.add(Bidirectional(LSTM(32, return_sequences=False, activation = 'relu')))\n",
        "# bilstm_model.add(Bidirectional(LSTM(units=128, return_sequences=True), input_shape=(60, 2048)))  # Adjust feature_size based on your data\n",
        "\n",
        "# Additional layers\n",
        "bilstm_model.add(Dense(64, activation='relu'))\n",
        "bilstm_model.add(Dense(32, activation='relu'))\n",
        "bilstm_model.add(Dense(noActions, activation = 'softmax'))\n",
        "\n",
        "# Combine the ResNet50 and BiLSTM models\n",
        "combined_input = Input(shape=(20, 224, 224, 3))  # Assuming image shape is (224, 224, 3)\n",
        "resnet_output = TimeDistributed(resnet_model)(combined_input)\n",
        "resnet_output = TimeDistributed(GlobalAveragePooling2D())(resnet_output)  # Adjust pooling layer based on your requirements\n",
        "# resnet_output = Reshape((60, -1))(resnet_output)\n",
        "# print(resnet_output.shape)\n",
        "bilstm_output = bilstm_model(resnet_output)\n",
        "\n",
        "# ---------------\n",
        "\n",
        "\n",
        "# Concatenate the outputs\n",
        "# merged = concatenate([resnet_output, bilstm_output])\n",
        "\n",
        "# Additional layers for combined model\n",
        "# final_output = Dense(128, activation='relu')(merged)\n",
        "# final_output = Dense(Dense(actions.shape[0], activation='softmax')(final_output)  # Adjust num_classes based on your task\n",
        "\n",
        "# Create the final model\n",
        "# hybrid_model = Model(inputs=combined_input, outputs=final_output)\n",
        "\n",
        "# ----------------\n",
        "hybrid_model1 = Model(inputs=combined_input, outputs=bilstm_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c5255150",
      "metadata": {
        "id": "c5255150"
      },
      "outputs": [],
      "source": [
        "def build_renet50():\n",
        "    resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    for layer in resnet_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # for layer in resnet_model.layers[:170]:\n",
        "    #     layer.trainable = False\n",
        "\n",
        "#     output = GlobalMaxPool2D()\n",
        "    return resnet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "4bf724f8",
      "metadata": {
        "id": "4bf724f8"
      },
      "outputs": [],
      "source": [
        "def build_BiLSTM(noActions, shape = (20, 2048)):\n",
        "\n",
        "    # Define the BiLSTM model\n",
        "    bilstm_model = Sequential()\n",
        "    # bilstm_model.add(TimeDistributed(first_model)(inputShape)) #(20, 2048)\n",
        "    bilstm_model.add(Bidirectional(LSTM(64, return_sequences=True, input_shape=shape))) #, input_shape=(60, 2048)\n",
        "    bilstm_model.add(Bidirectional(LSTM(32, return_sequences=False)))\n",
        "\n",
        "    # Additional layers\n",
        "    # bilstm_model.add(Flatten())\n",
        "    # bilstm_model.add(Dense(64, activation='relu'))\n",
        "    # bilstm_model.add(Dropout(.5))\n",
        "    # bilstm_model.add(Dense(128, activation='relu'))\n",
        "    # bilstm_model.add(Dropout(.5))\n",
        "    # bilstm_model.add(Dense(64, activation='relu'))\n",
        "    # bilstm_model.add(Dropout(.5))\n",
        "    # bilstm_model.add(Dense(32, activation='relu'))\n",
        "    # bilstm_model.add(Dense(noActions, activation = 'softmax'))\n",
        "\n",
        "    bilstm_model.add(BatchNormalization())\n",
        "    bilstm_model.add(Dense(256, activation='relu'))\n",
        "    bilstm_model.add(BatchNormalization())\n",
        "    bilstm_model.add(Dense(128, activation='relu'))\n",
        "    bilstm_model.add(Dropout(0.5))\n",
        "    bilstm_model.add(BatchNormalization())\n",
        "    bilstm_model.add(Dense(64, activation='relu'))\n",
        "    bilstm_model.add(Dropout(0.5))\n",
        "    bilstm_model.add(BatchNormalization())\n",
        "    bilstm_model.add(Dense(noActions, activation='softmax'))\n",
        "\n",
        "    return bilstm_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c015b470",
      "metadata": {
        "id": "c015b470"
      },
      "outputs": [],
      "source": [
        "def Res50_BiLSTM(inputShape=(20,224,224,3), noActions=len(subset_video_count.keys())):\n",
        "    combined_input = Input(shape=inputShape)  # Assuming image shape is (224, 224, 3)\n",
        "    resnetModel = build_renet50()\n",
        "    resnet_output = TimeDistributed(resnetModel)(combined_input)\n",
        "    resnet_output = TimeDistributed(GlobalAveragePooling2D())(resnet_output)\n",
        "    bilstm_model = build_BiLSTM(noActions, (20, 2048))\n",
        "    bilstm_output = bilstm_model(resnet_output)\n",
        "    hybrid_model1 = Model(inputs=combined_input, outputs=bilstm_output)\n",
        "    return hybrid_model1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "28455647",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a learning rate schedule function\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def lr_schedule(epoch, current_lr):\n",
        "    if epoch < 3:\n",
        "        return current_lr  # Keep the initial learning rate for the first 5 epochs\n",
        "    else:\n",
        "        # Increase the learning rate by 3 times after the 5th epoch\n",
        "        return current_lr * 0.1\n",
        "    \n",
        "\n",
        "# Create a learning rate scheduler\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7d241830",
      "metadata": {
        "id": "7d241830"
      },
      "outputs": [],
      "source": [
        "Res50_BiLSTM_1 = Res50_BiLSTM()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a30e38eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# #--------------------------------------------------\n",
        "# resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "# resnet_model.trainable = False  # Freeze the weights of the ResNet50 model\n",
        "\n",
        "# noActions = len(subset_video_count.keys())\n",
        "\n",
        "# # Define the BiLSTM model\n",
        "# bilstm_model = Sequential()\n",
        "# bilstm_model.add(Bidirectional(LSTM(64, return_sequences=True, activation='relu', input_shape=(20, 2048))))\n",
        "# bilstm_model.add(Bidirectional(LSTM(32, return_sequences=False, activation='relu')))\n",
        "\n",
        "# # Additional layers\n",
        "# bilstm_model.add(Flatten())\n",
        "# bilstm_model.add(Dense(128, activation='relu'))\n",
        "# bilstm_model.add(Dropout(.5))\n",
        "# bilstm_model.add(Dense(64, activation='relu'))\n",
        "# bilstm_model.add(Dropout(.5))\n",
        "# bilstm_model.add(Dense(32, activation='relu'))\n",
        "# bilstm_model.add(Dense(noActions, activation = 'softmax'))\n",
        "\n",
        "# combined_input = Input(shape=(20, 224, 224, 3))  # Assuming image shape is (224, 224, 3)\n",
        "# resnet_output = TimeDistributed(resnet_model())(combined_input)\n",
        "# resnet_output = TimeDistributed(GlobalAveragePooling2D())(resnet_output)\n",
        "# bilstm_output = bilstm_model(resnet_output)\n",
        "# Res50_BiLSTM_1 = Model(inputs=combined_input, outputs=bilstm_output)\n",
        "\n",
        "# #--------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e74a436d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "# from keras.optimizers import Adam, RMSprop, SVM\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "a2b9a29d",
      "metadata": {
        "id": "a2b9a29d"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "# Res50_BiLSTM_1.compile(optimizer=RMSprop(learning_rate=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "Res50_BiLSTM_1.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "75bfe002",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 20, 224, 224, 3)] 0         \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 20, 7, 7, 2048)    23587712  \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 20, 2048)          0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 4)                 1183172   \n",
            "=================================================================\n",
            "Total params: 24,770,884\n",
            "Trainable params: 1,182,148\n",
            "Non-trainable params: 23,588,736\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "Res50_BiLSTM_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "113ebabe",
      "metadata": {
        "id": "113ebabe"
      },
      "outputs": [],
      "source": [
        "batch_size = 2\n",
        "epochs = 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ec1fef5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "with tf.device('/cpu:0'):\n",
        "   x = tf.convert_to_tensor(X_train, np.float32)\n",
        "   y = tf.convert_to_tensor(y_train, np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "8FAcVzbGCWmU",
      "metadata": {
        "id": "8FAcVzbGCWmU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "86/86 [==============================] - 21s 124ms/step - loss: 1.6086 - accuracy: 0.2456 - val_loss: 153.2892 - val_accuracy: 0.4444\n",
            "Epoch 2/7\n",
            "86/86 [==============================] - 8s 94ms/step - loss: 1.5351 - accuracy: 0.2573 - val_loss: 80.8989 - val_accuracy: 0.4444\n",
            "Epoch 3/7\n",
            "86/86 [==============================] - 8s 94ms/step - loss: 1.5545 - accuracy: 0.2515 - val_loss: 316.3369 - val_accuracy: 0.4444\n",
            "Epoch 4/7\n",
            "86/86 [==============================] - 8s 94ms/step - loss: 1.5110 - accuracy: 0.2398 - val_loss: 191.3707 - val_accuracy: 0.4444\n",
            "Epoch 5/7\n",
            "86/86 [==============================] - 8s 95ms/step - loss: 1.4292 - accuracy: 0.2924 - val_loss: 129.3690 - val_accuracy: 0.4444\n",
            "Epoch 6/7\n",
            "86/86 [==============================] - 8s 95ms/step - loss: 1.4952 - accuracy: 0.2398 - val_loss: 129.4275 - val_accuracy: 0.2222\n",
            "Epoch 7/7\n",
            "86/86 [==============================] - 8s 95ms/step - loss: 1.4606 - accuracy: 0.2632 - val_loss: 101.1790 - val_accuracy: 0.1111\n"
          ]
        }
      ],
      "source": [
        "history1_1  = Res50_BiLSTM_1.fit(x, y, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), callbacks = [checkpoint, earlyStopping])  # Adjust epochs and batch_size accordingly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01fba749",
      "metadata": {},
      "outputs": [],
      "source": [
        "history1_2  = Res50_BiLSTM_1.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), callbacks = [checkpoint, earlyStopping])  # Adjust epochs and batch_size accordingly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db41abca",
      "metadata": {
        "id": "db41abca",
        "outputId": "b395283c-9eb1-47b9-8e3a-519ec1fe06d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34/34 [==============================] - 163s 5s/step - loss: 1.4542 - accuracy: 0.4118 - val_loss: 0.7121 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "# history1  = hybrid_model1.fit(X, y, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks = [checkpoint, earlyStopping])  # Adjust epochs and batch_size accordingly\n",
        "# history1_2  = hybrid_model1_1.fit(X, y, epochs=epochs, batch_size=batch_size, callbacks = [checkpoint])  # Adjust epochs and batch_size accordingly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "c08074a8",
      "metadata": {
        "id": "c08074a8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.877019</td>\n",
              "      <td>0.233918</td>\n",
              "      <td>1.384041</td>\n",
              "      <td>0.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.728266</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>1.311437</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.774276</td>\n",
              "      <td>0.204678</td>\n",
              "      <td>1.284750</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.647648</td>\n",
              "      <td>0.309942</td>\n",
              "      <td>1.260195</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy  val_loss  val_accuracy\n",
              "0  1.877019  0.233918  1.384041      0.111111\n",
              "1  1.728266  0.263158  1.311437      0.444444\n",
              "2  1.774276  0.204678  1.284750      0.333333\n",
              "3  1.647648  0.309942  1.260195      0.222222"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics_df = pd.DataFrame(history1_1.history)\n",
        "metrics_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4638a03e",
      "metadata": {},
      "source": [
        "### CNN + BiLSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18416963",
      "metadata": {
        "id": "18416963"
      },
      "source": [
        "CNN + BiLSTM (224 x 224 images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "c3d4d370",
      "metadata": {
        "id": "c3d4d370"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aafca8d0",
      "metadata": {
        "id": "aafca8d0",
        "outputId": "69140757-e710-49d7-bf32-f2d2b2773fe4"
      },
      "outputs": [],
      "source": [
        "# Assuming you have a ResNet50 model loaded with pre-trained weights\n",
        "cnn_model = models.Sequential()\n",
        "cnn_model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "cnn_model.add(layers.MaxPooling2D()) #(2,2)\n",
        "cnn_model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "cnn_model.add(layers.MaxPooling2D())\n",
        "cnn_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "cnn_model.add(layers.MaxPooling2D())\n",
        "cnn_model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "actions = len(subset_video_count.keys())\n",
        "\n",
        "# Define the BiLSTM model\n",
        "bilstm_model = Sequential()\n",
        "# bilstm_model.add(Bidirectional(LSTM(64, return_sequences=True, activation = 'relu', input_shape = (60,2048))))\n",
        "bilstm_model.add(Bidirectional(LSTM(64, return_sequences=True, activation='relu'), input_shape=(60, 2048)))\n",
        "bilstm_model.add(Bidirectional(LSTM(32, return_sequences=False, activation = 'relu')))\n",
        "# bilstm_model.add(Bidirectional(LSTM(units=128, return_sequences=True), input_shape=(60, 2048)))  # Adjust feature_size based on your data\n",
        "\n",
        "# Additional layers\n",
        "bilstm_model.add(layers.Flatten())  # new added line -> (Dense layers take vectors as input (which are 1D), while the current output is a 3D tensor.)\n",
        "bilstm_model.add(Dense(64, activation='relu'))\n",
        "bilstm_model.add(Dense(32, activation='relu'))\n",
        "bilstm_model.add(Dense(actions, activation = 'softmax'))\n",
        "\n",
        "# Combine the ResNet50 and BiLSTM models\n",
        "combined_input = Input(shape=(20, 224, 224, 3))  # Assuming image shape is (224, 224, 3)\n",
        "cnn_output = TimeDistributed(cnn_model)(combined_input)\n",
        "cnn_output = TimeDistributed(GlobalAveragePooling2D())(cnn_model)  # Adjust pooling layer based on your requirements\n",
        "# resnet_output = Reshape((60, -1))(resnet_output)\n",
        "# print(resnet_output.shape)\n",
        "bilstm_output = bilstm_model(cnn_output)\n",
        "\n",
        "# ---------------\n",
        "\n",
        "\n",
        "# Concatenate the outputs\n",
        "# merged = concatenate([resnet_output, bilstm_output])\n",
        "\n",
        "# Additional layers for combined model\n",
        "# final_output = Dense(128, activation='relu')(merged)\n",
        "# final_output = Dense(Dense(actions.shape[0], activation='softmax')(final_output)  # Adjust num_classes based on your task\n",
        "\n",
        "# Create the final model\n",
        "# hybrid_model = Model(inputs=combined_input, outputs=final_output)\n",
        "\n",
        "# ----------------\n",
        "hybrid_model2 = Model(inputs=combined_input, outputs=bilstm_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "9465718a",
      "metadata": {
        "id": "9465718a"
      },
      "outputs": [],
      "source": [
        "def build_cnn(shape=(224, 224, 3)):\n",
        "    cnn_model = models.Sequential()\n",
        "    cnn_model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3), strides=1))\n",
        "    cnn_model.add(BatchNormalization(momentum=0.9))\n",
        "    cnn_model.add(MaxPooling2D((2,2), strides=2)) #(2,2)\n",
        "    cnn_model.add(Conv2D(128, (3, 3), activation='relu', strides=1))\n",
        "    cnn_model.add(BatchNormalization(momentum=0.9))\n",
        "    cnn_model.add(MaxPooling2D((2,2), strides=2))\n",
        "    cnn_model.add(Conv2D(64, (3, 3), activation='relu', strides=1))\n",
        "    cnn_model.add(BatchNormalization(momentum=0.9))\n",
        "    cnn_model.add(MaxPooling2D((2,2), strides=2))\n",
        "    cnn_model.add(Conv2D(32, (3, 3), activation='relu', strides=1))\n",
        "    # output = GlobalMaxPool2D()\n",
        "\n",
        "    return cnn_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "8d49b596",
      "metadata": {
        "id": "8d49b596"
      },
      "outputs": [],
      "source": [
        "def build_BiLSTM1(noActions, shape = (20, 2048)):\n",
        "    # cnn_model = build_cnn(shape[1:])\n",
        "\n",
        "    # Define the BiLSTM model\n",
        "    bilstm_model = Sequential()\n",
        "    # bilstm_model.add(TimeDistributed(first_model)(inputShape)) #(20, 2048)\n",
        "    bilstm_model.add(Bidirectional(LSTM(64, return_sequences=True, input_shape=shape))) #, input_shape=(60, 2048)\n",
        "    bilstm_model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "    bilstm_model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "    bilstm_model.add(Bidirectional(LSTM(32, return_sequences=False)))\n",
        "\n",
        "    # Additional layers\n",
        "    bilstm_model.add(Dense(128, activation='relu'))\n",
        "    bilstm_model.add(Dropout(.5))\n",
        "    bilstm_model.add(Dense(64, activation='relu'))\n",
        "    bilstm_model.add(Dropout(.5))\n",
        "    bilstm_model.add(Dense(32, activation='relu'))\n",
        "    bilstm_model.add(Dense(noActions, activation = 'softmax'))\n",
        "\n",
        "    return bilstm_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "ba3b3955",
      "metadata": {},
      "outputs": [],
      "source": [
        "def CNN_BiLSTM(inputShape=(20,224,224,3), noActions=len(subset_video_count.keys())):\n",
        "    combined_input = Input(shape=inputShape)  # Assuming image shape is (224, 224, 3)\n",
        "    cnnModel = build_cnn()\n",
        "    cnn_output = TimeDistributed(cnnModel)(combined_input)\n",
        "    cnn_output = TimeDistributed(GlobalMaxPool2D())(cnn_output)\n",
        "    bilstm_model = build_BiLSTM1(noActions, (20, 2048))\n",
        "    bilstm_output = bilstm_model(cnn_output)\n",
        "    hybrid_model2 = Model(inputs=combined_input, outputs=bilstm_output)\n",
        "    return hybrid_model2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "3c1c20a5",
      "metadata": {
        "id": "3c1c20a5"
      },
      "outputs": [],
      "source": [
        "CNN_BiLSTM_1 = CNN_BiLSTM()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "776d8cc2",
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 2\n",
        "epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "92cf88d4",
      "metadata": {
        "id": "92cf88d4"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "CNN_BiLSTM_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "952cc5ce",
      "metadata": {
        "id": "952cc5ce",
        "outputId": "394243b6-3823-4817-f3d5-79e01845e7c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "86/86 [==============================] - 27s 182ms/step - loss: 1.3986 - accuracy: 0.2632 - val_loss: 1.4303 - val_accuracy: 0.2222\n",
            "Epoch 2/5\n",
            "86/86 [==============================] - 13s 152ms/step - loss: 1.4294 - accuracy: 0.2339 - val_loss: 1.4040 - val_accuracy: 0.2222\n",
            "Epoch 3/5\n",
            "86/86 [==============================] - 13s 153ms/step - loss: 1.3968 - accuracy: 0.2690 - val_loss: 1.3923 - val_accuracy: 0.2222\n",
            "Epoch 4/5\n",
            "86/86 [==============================] - 13s 153ms/step - loss: 1.4022 - accuracy: 0.2339 - val_loss: 1.3916 - val_accuracy: 0.1111\n",
            "Epoch 5/5\n",
            "86/86 [==============================] - 13s 153ms/step - loss: 1.4086 - accuracy: 0.2164 - val_loss: 1.3916 - val_accuracy: 0.1111\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history2_1 = CNN_BiLSTM_1.fit(x, y, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))  # Adjust epochs and batch_size accordingly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec7c27fa",
      "metadata": {
        "id": "ec7c27fa"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history2 = hybrid_model2.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), callbacks = [checkpoint, earlyStopping])  # Adjust epochs and batch_size accordingly"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc749b03",
      "metadata": {},
      "source": [
        "### Xception + BiLSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb46aa3d",
      "metadata": {
        "id": "bb46aa3d"
      },
      "source": [
        "Xception + BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e0139f7",
      "metadata": {
        "id": "0e0139f7"
      },
      "outputs": [],
      "source": [
        "# Assuming you have a ResNet50 model loaded with pre-trained weights\n",
        "Xnet_model=tf.keras.applications.xception.Xception(weights='imagenet',include_top=False, input_shape = (224, 224, 3))\n",
        "Xnet_model.trainable = False\n",
        "\n",
        "actions = len(subset_video_count.keys())\n",
        "\n",
        "# Define the BiLSTM model\n",
        "bilstm_model = Sequential()\n",
        "# bilstm_model.add(Bidirectional(LSTM(64, return_sequences=True, activation = 'relu', input_shape = (60,2048))))\n",
        "bilstm_model.add(Bidirectional(LSTM(64, return_sequences=True, activation='relu'), input_shape=(60, 2048)))\n",
        "bilstm_model.add(Bidirectional(LSTM(32, return_sequences=False, activation = 'relu')))\n",
        "# bilstm_model.add(Bidirectional(LSTM(units=128, return_sequences=True), input_shape=(60, 2048)))  # Adjust feature_size based on your data\n",
        "\n",
        "# Additional layers\n",
        "# bilstm_model.add(layers.Flatten())  # new added line -> (Dense layers take vectors as input (which are 1D), while the current output is a 3D tensor.)\n",
        "bilstm_model.add(Dense(64, activation='relu'))\n",
        "bilstm_model.add(Dense(32, activation='relu'))\n",
        "bilstm_model.add(Dense(actions, activation = 'softmax'))\n",
        "\n",
        "# Combine the ResNet50 and BiLSTM models\n",
        "combined_input = Input(shape=(60, 224, 224, 3))  # Assuming image shape is (224, 224, 3)\n",
        "Xnet_output = TimeDistributed(Xnet_model)(combined_input)\n",
        "Xnet_output = TimeDistributed(GlobalAveragePooling2D())(Xnet_model)  # Adjust pooling layer based on your requirements\n",
        "# resnet_output = Reshape((60, -1))(resnet_output)\n",
        "# print(resnet_output.shape)\n",
        "bilstm_output = bilstm_model(Xnet_output)\n",
        "\n",
        "# ---------------\n",
        "\n",
        "\n",
        "# Concatenate the outputs\n",
        "# merged = concatenate([resnet_output, bilstm_output])\n",
        "\n",
        "# Additional layers for combined model\n",
        "# final_output = Dense(128, activation='relu')(merged)\n",
        "# final_output = Dense(Dense(actions.shape[0], activation='softmax')(final_output)  # Adjust num_classes based on your task\n",
        "\n",
        "# Create the final model\n",
        "# hybrid_model = Model(inputs=combined_input, outputs=final_output)\n",
        "\n",
        "# ----------------\n",
        "hybrid_model3 = Model(inputs=combined_input, outputs=bilstm_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3796679a",
      "metadata": {
        "id": "3796679a"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "hybrid_model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd9175aa",
      "metadata": {
        "id": "dd9175aa",
        "outputId": "6ee48cfb-e6bf-43b1-cf78-c601331b7800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 60, 224, 224, 3   0         \n",
            "                             )]                                  \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 60, 7, 7, 2048)    23587712  \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDi  (None, 60, 2048)          0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 3)                 1129411   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24717123 (94.29 MB)\n",
            "Trainable params: 1129411 (4.31 MB)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Display model summary\n",
        "hybrid_model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62c69ec6",
      "metadata": {
        "id": "62c69ec6"
      },
      "outputs": [],
      "source": [
        "batch_size = 2\n",
        "# frames = 60\n",
        "epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3b1b702",
      "metadata": {
        "id": "c3b1b702",
        "outputId": "9ec68887-b8ef-4811-fd71-7732630cf989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "40/40 [==============================] - ETA: 0s - loss: 2981.3291 - accuracy: 0.3625WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "40/40 [==============================] - 264s 6s/step - loss: 2981.3291 - accuracy: 0.3625 - val_loss: 3343.4873 - val_accuracy: 0.4444\n",
            "Epoch 2/5\n",
            "40/40 [==============================] - ETA: 0s - loss: 10839.7988 - accuracy: 0.2375WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "40/40 [==============================] - 246s 6s/step - loss: 10839.7988 - accuracy: 0.2375 - val_loss: 35102.9688 - val_accuracy: 0.3333\n",
            "Epoch 3/5\n",
            "40/40 [==============================] - ETA: 0s - loss: 38513.8633 - accuracy: 0.3125WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "40/40 [==============================] - 246s 6s/step - loss: 38513.8633 - accuracy: 0.3125 - val_loss: 29871.4375 - val_accuracy: 0.3333\n",
            "Epoch 4/5\n",
            "40/40 [==============================] - ETA: 0s - loss: 19742.9902 - accuracy: 0.3625WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "40/40 [==============================] - 245s 6s/step - loss: 19742.9902 - accuracy: 0.3625 - val_loss: 101186.1094 - val_accuracy: 0.1111\n",
            "Epoch 5/5\n",
            "40/40 [==============================] - ETA: 0s - loss: 43741.2734 - accuracy: 0.3875WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "40/40 [==============================] - 249s 6s/step - loss: 43741.2734 - accuracy: 0.3875 - val_loss: 18177.5293 - val_accuracy: 0.3333\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1c38e59f6d0>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "history1  = hybrid_model1.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks = [checkpoint, earlyStopping])  # Adjust epochs and batch_size accordingly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CR4rIK_NBDvG",
      "metadata": {
        "id": "CR4rIK_NBDvG"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history1  = hybrid_model1.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks = [checkpoint, earlyStopping])  # Adjust epochs and batch_size accordingly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6bf20d2",
      "metadata": {
        "id": "e6bf20d2"
      },
      "outputs": [],
      "source": [
        "# history1 = model.fit(X_train, y_train, epochs=5,\n",
        "#                     validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25a322f0",
      "metadata": {
        "id": "25a322f0"
      },
      "outputs": [],
      "source": [
        "# hybrid_model1.save('RES50BiModel_sub.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "171cdc8c",
      "metadata": {
        "id": "171cdc8c",
        "outputId": "58635ac0-81d7-46fd-9114-71faa504bfb4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dr2007\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# hybrid_model1.save(\"RES50BiModel_sub.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02b31773",
      "metadata": {
        "id": "02b31773"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "834621b1",
      "metadata": {
        "id": "834621b1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ce2bbe96",
      "metadata": {
        "id": "ce2bbe96"
      },
      "source": [
        "## Monitoring the Model's performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec95797d",
      "metadata": {
        "id": "ec95797d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "43f9c37f",
      "metadata": {
        "id": "43f9c37f"
      },
      "outputs": [],
      "source": [
        "metrics_df = pd.DataFrame(history1.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "fa10d5ff",
      "metadata": {
        "id": "fa10d5ff",
        "outputId": "0e5fe132-66c0-4336-aa6a-fc24738a4d9d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>62.605747</td>\n",
              "      <td>0.338843</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>39.752792</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>2.623568</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30.507166</td>\n",
              "      <td>0.305785</td>\n",
              "      <td>0.458849</td>\n",
              "      <td>0.785714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13.065916</td>\n",
              "      <td>0.264463</td>\n",
              "      <td>2.186147</td>\n",
              "      <td>0.214286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.814025</td>\n",
              "      <td>0.347107</td>\n",
              "      <td>0.806707</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy\n",
              "0  62.605747  0.338843  0.000000      1.000000\n",
              "1  39.752792  0.272727  2.623568      0.142857\n",
              "2  30.507166  0.305785  0.458849      0.785714\n",
              "3  13.065916  0.264463  2.186147      0.214286\n",
              "4   7.814025  0.347107  0.806707      0.428571"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "3d920073",
      "metadata": {
        "id": "3d920073",
        "outputId": "10023754-2948-40e0-bc2d-de8b508ba108"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# comparing the training and validation loss.\n",
        "metrics_df[[\"loss\",\"val_loss\"]].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "5e9e158b",
      "metadata": {
        "id": "5e9e158b",
        "outputId": "91734bab-51a6-419d-cfa5-45dc19243c9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# comparing the training and validation accuracy.\n",
        "metrics_df[[\"accuracy\",\"val_accuracy\"]].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da6fa78f",
      "metadata": {
        "id": "da6fa78f"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b275fe2",
      "metadata": {
        "id": "4b275fe2",
        "outputId": "d3aa4d81-4eeb-4631-9f01-783b57b3270a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 24s 24s/step - loss: 17.1240 - accuracy: 0.5000\n",
            "Accuracy on validation dataset: 0.5\n",
            "Loss on validation dataset: 17.123992919921875\n"
          ]
        }
      ],
      "source": [
        "val_loss, val_accuracy = hybrid_model1.evaluate(X_val, y_val)\n",
        "print('Accuracy on validation dataset:', val_accuracy)\n",
        "print('Loss on validation dataset:', val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4064807f",
      "metadata": {
        "id": "4064807f"
      },
      "outputs": [],
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print('Accuracy on test dataset:', val_accuracy)\n",
        "print('Loss on test dataset:', val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08d38f9e",
      "metadata": {
        "id": "08d38f9e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbe17e75",
      "metadata": {
        "id": "bbe17e75"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25186f60",
      "metadata": {
        "id": "25186f60"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "13f5a983",
        "e195f4da",
        "b6ae7098",
        "086f9e04",
        "0dc1285b",
        "3b725def",
        "d4526c39",
        "61a303a8",
        "944047ec",
        "26bac943",
        "687f20f4",
        "7aK5lyRKAB6c",
        "9cd7e79b"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
